{"episode": 0.0, "episode_reward": 195.8, "eval_time": 29.029059410095215, "mean_episode_reward": 195.8, "best_episode_reward": 996.0, "step": 0}
{"episode": 40.0, "episode_reward": 574.5, "eval_time": 31.14958095550537, "mean_episode_reward": 574.5, "best_episode_reward": 993.0, "step": 10000}
{"episode": 80.0, "episode_reward": 478.1, "eval_time": 21.10360813140869, "mean_episode_reward": 478.1, "best_episode_reward": 979.0, "step": 20000}
{"episode": 120.0, "episode_reward": 943.3, "eval_time": 20.39469861984253, "mean_episode_reward": 943.3, "best_episode_reward": 994.0, "step": 30000}
{"episode": 160.0, "episode_reward": 909.6, "eval_time": 20.78610110282898, "mean_episode_reward": 909.6, "best_episode_reward": 989.0, "step": 40000}
{"episode": 200.0, "episode_reward": 944.7, "eval_time": 20.545186042785645, "mean_episode_reward": 944.7, "best_episode_reward": 994.0, "step": 50000}
{"episode": 240.0, "episode_reward": 908.9, "eval_time": 20.77500057220459, "mean_episode_reward": 908.9, "best_episode_reward": 965.0, "step": 60000}
{"episode": 280.0, "episode_reward": 952.2, "eval_time": 20.767232179641724, "mean_episode_reward": 952.2, "best_episode_reward": 966.0, "step": 70000}
{"episode": 320.0, "episode_reward": 965.0, "eval_time": 20.507325887680054, "mean_episode_reward": 965.0, "best_episode_reward": 1000.0, "step": 80000}
{"episode": 360.0, "episode_reward": 965.7, "eval_time": 21.042675018310547, "mean_episode_reward": 965.7, "best_episode_reward": 992.0, "step": 90000}
{"episode": 400.0, "episode_reward": 959.2, "eval_time": 20.382564067840576, "mean_episode_reward": 959.2, "best_episode_reward": 995.0, "step": 100000}
{"episode": 440.0, "episode_reward": 974.1, "eval_time": 20.205097913742065, "mean_episode_reward": 974.1, "best_episode_reward": 992.0, "step": 110000}
{"episode": 480.0, "episode_reward": 969.8, "eval_time": 20.644339084625244, "mean_episode_reward": 969.8, "best_episode_reward": 997.0, "step": 120000}
{"episode": 520.0, "episode_reward": 973.5, "eval_time": 20.80707812309265, "mean_episode_reward": 973.5, "best_episode_reward": 995.0, "step": 130000}
{"episode": 560.0, "episode_reward": 969.4, "eval_time": 20.474350214004517, "mean_episode_reward": 969.4, "best_episode_reward": 998.0, "step": 140000}
{"episode": 600.0, "episode_reward": 962.1, "eval_time": 20.57610774040222, "mean_episode_reward": 962.1, "best_episode_reward": 993.0, "step": 150000}
{"episode": 640.0, "episode_reward": 980.4, "eval_time": 20.53139090538025, "mean_episode_reward": 980.4, "best_episode_reward": 1000.0, "step": 160000}
{"episode": 680.0, "episode_reward": 970.1, "eval_time": 20.555495738983154, "mean_episode_reward": 970.1, "best_episode_reward": 997.0, "step": 170000}
{"episode": 720.0, "episode_reward": 974.7, "eval_time": 20.795061349868774, "mean_episode_reward": 974.7, "best_episode_reward": 999.0, "step": 180000}
{"episode": 760.0, "episode_reward": 966.3, "eval_time": 20.516792058944702, "mean_episode_reward": 966.3, "best_episode_reward": 997.0, "step": 190000}
{"episode": 800.0, "episode_reward": 978.7, "eval_time": 20.858338594436646, "mean_episode_reward": 978.7, "best_episode_reward": 994.0, "step": 200000}
{"episode": 840.0, "episode_reward": 978.5, "eval_time": 20.93350315093994, "mean_episode_reward": 978.5, "best_episode_reward": 992.0, "step": 210000}
{"episode": 880.0, "episode_reward": 978.6, "eval_time": 20.742879152297974, "mean_episode_reward": 978.6, "best_episode_reward": 1000.0, "step": 220000}
{"episode": 920.0, "episode_reward": 970.2, "eval_time": 20.182201147079468, "mean_episode_reward": 970.2, "best_episode_reward": 997.0, "step": 230000}
{"episode": 960.0, "episode_reward": 984.5, "eval_time": 20.365233182907104, "mean_episode_reward": 984.5, "best_episode_reward": 1000.0, "step": 240000}
{"episode": 1000.0, "episode_reward": 978.8, "eval_time": 20.549322366714478, "mean_episode_reward": 978.8, "best_episode_reward": 1000.0, "step": 250000}
{"episode": 1040.0, "episode_reward": 975.8, "eval_time": 20.814911127090454, "mean_episode_reward": 975.8, "best_episode_reward": 996.0, "step": 260000}
{"episode": 1080.0, "episode_reward": 976.8, "eval_time": 20.47562885284424, "mean_episode_reward": 976.8, "best_episode_reward": 991.0, "step": 270000}
{"episode": 1120.0, "episode_reward": 978.7, "eval_time": 20.479931831359863, "mean_episode_reward": 978.7, "best_episode_reward": 992.0, "step": 280000}
{"episode": 1160.0, "episode_reward": 976.9, "eval_time": 20.52261710166931, "mean_episode_reward": 976.9, "best_episode_reward": 997.0, "step": 290000}
{"episode": 1200.0, "episode_reward": 975.5, "eval_time": 20.45822238922119, "mean_episode_reward": 975.5, "best_episode_reward": 998.0, "step": 300000}
{"episode": 1240.0, "episode_reward": 973.5, "eval_time": 20.66973042488098, "mean_episode_reward": 973.5, "best_episode_reward": 1000.0, "step": 310000}
{"episode": 1280.0, "episode_reward": 973.3, "eval_time": 21.68193769454956, "mean_episode_reward": 973.3, "best_episode_reward": 998.0, "step": 320000}
{"episode": 1320.0, "episode_reward": 984.0, "eval_time": 20.383312463760376, "mean_episode_reward": 984.0, "best_episode_reward": 999.0, "step": 330000}
{"episode": 1360.0, "episode_reward": 973.9, "eval_time": 20.374929904937744, "mean_episode_reward": 973.9, "best_episode_reward": 1000.0, "step": 340000}
{"episode": 1400.0, "episode_reward": 981.3, "eval_time": 20.70508575439453, "mean_episode_reward": 981.3, "best_episode_reward": 997.0, "step": 350000}
{"episode": 1440.0, "episode_reward": 972.6, "eval_time": 20.74844479560852, "mean_episode_reward": 972.6, "best_episode_reward": 997.0, "step": 360000}
{"episode": 1480.0, "episode_reward": 978.7, "eval_time": 20.423063278198242, "mean_episode_reward": 978.7, "best_episode_reward": 991.0, "step": 370000}
{"episode": 1520.0, "episode_reward": 970.3, "eval_time": 20.557003498077393, "mean_episode_reward": 970.3, "best_episode_reward": 998.0, "step": 380000}
{"episode": 1560.0, "episode_reward": 976.4, "eval_time": 20.72458052635193, "mean_episode_reward": 976.4, "best_episode_reward": 995.0, "step": 390000}
{"episode": 1600.0, "episode_reward": 976.6, "eval_time": 20.848925828933716, "mean_episode_reward": 976.6, "best_episode_reward": 992.0, "step": 400000}
{"episode": 1640.0, "episode_reward": 978.2, "eval_time": 20.370755910873413, "mean_episode_reward": 978.2, "best_episode_reward": 1000.0, "step": 410000}
{"episode": 1680.0, "episode_reward": 984.1, "eval_time": 20.717194318771362, "mean_episode_reward": 984.1, "best_episode_reward": 996.0, "step": 420000}
{"episode": 1720.0, "episode_reward": 973.6, "eval_time": 20.52061176300049, "mean_episode_reward": 973.6, "best_episode_reward": 1000.0, "step": 430000}
{"episode": 1760.0, "episode_reward": 984.6, "eval_time": 20.886932373046875, "mean_episode_reward": 984.6, "best_episode_reward": 1000.0, "step": 440000}
{"episode": 1800.0, "episode_reward": 979.7, "eval_time": 20.765483140945435, "mean_episode_reward": 979.7, "best_episode_reward": 992.0, "step": 450000}
{"episode": 1840.0, "episode_reward": 978.0, "eval_time": 22.218976497650146, "mean_episode_reward": 978.0, "best_episode_reward": 991.0, "step": 460000}
{"episode": 1880.0, "episode_reward": 975.9, "eval_time": 20.482062578201294, "mean_episode_reward": 975.9, "best_episode_reward": 997.0, "step": 470000}
{"episode": 1920.0, "episode_reward": 977.5, "eval_time": 20.445725202560425, "mean_episode_reward": 977.5, "best_episode_reward": 1000.0, "step": 480000}
{"episode": 1960.0, "episode_reward": 984.0, "eval_time": 21.075361967086792, "mean_episode_reward": 984.0, "best_episode_reward": 996.0, "step": 490000}
